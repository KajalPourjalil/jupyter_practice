{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009c09dc",
   "metadata": {},
   "source": [
    "## importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e639397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71023a62",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be5fa5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\469455691.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  eng_df = pd.read_csv(\"english_demo.txt\", \"utf-8\", header=None, names = [\"English\"])\n",
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\469455691.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  eng_df = pd.read_csv(\"english_demo.txt\", \"utf-8\", header=None, names = [\"English\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I woke up early this morning and enjoyed a pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English\n",
       "0  \"I woke up early this morning and enjoyed a pe..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_df = pd.read_csv(\"english_demo.txt\", \"utf-8\", header=None, names = [\"English\"])\n",
    "eng_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cdc6f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\2459620830.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  tur_df = pd.read_csv(\"tur_demo.txt\", \"utf-8\", header=None, names=[\"Turkish\"])\n",
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\2459620830.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  tur_df = pd.read_csv(\"tur_demo.txt\", \"utf-8\", header=None, names=[\"Turkish\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Bu sabah erken kalktım ve parkta huzurlu bir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Turkish\n",
       "0  \"Bu sabah erken kalktım ve parkta huzurlu bir ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tur_df = pd.read_csv(\"tur_demo.txt\", \"utf-8\", header=None, names=[\"Turkish\"])\n",
    "tur_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb6b6ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\3737396593.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  far_df = pd.read_csv(\"far_demo.txt\", \"utf-8\", header=None, names=[\"Farsi\"])\n",
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\3737396593.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  far_df = pd.read_csv(\"far_demo.txt\", \"utf-8\", header=None, names=[\"Farsi\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Farsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"امروز صبح زود بیدار شدم و یک قدم آرام در پارک...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Farsi\n",
       "0  \"امروز صبح زود بیدار شدم و یک قدم آرام در پارک..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_df = pd.read_csv(\"far_demo.txt\", \"utf-8\", header=None, names=[\"Farsi\"])\n",
    "far_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2353c47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\3679146891.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  jap_df = pd.read_csv(\"jap_demo.txt\", \"utf-8\", header=None, names=[\"Japanese\"])\n",
      "C:\\Users\\tivadigi\\AppData\\Local\\Temp\\ipykernel_19632\\3679146891.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  jap_df = pd.read_csv(\"jap_demo.txt\", \"utf-8\", header=None, names=[\"Japanese\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Japanese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(日本語):</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"今朝は早く起きて、公園で静かな散歩を楽しみました。やわらかな葉のさらさらという音や鳥のさえ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Japanese\n",
       "0                                             (日本語):\n",
       "1  \"今朝は早く起きて、公園で静かな散歩を楽しみました。やわらかな葉のさらさらという音や鳥のさえ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jap_df = pd.read_csv(\"jap_demo.txt\", \"utf-8\", header=None, names=[\"Japanese\"])\n",
    "jap_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a50636",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "526257ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~ "
     ]
    }
   ],
   "source": [
    "for char in string.punctuation:\n",
    "    print(char, end=\" \")\n",
    "translate_table = dict((ord(char), None) for char in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a866aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eng = []\n",
    "lang_eng = []\n",
    "\n",
    "for i,line in eng_df.iterrows():\n",
    "    line = line['English']\n",
    "    if len(line) != 0:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = line.translate(translate_table)\n",
    "        data_eng.append(line)\n",
    "        lang_eng.append(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "942627b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tur = []\n",
    "lang_tur = []\n",
    "\n",
    "for i,line in tur_df.iterrows():\n",
    "    line = line['Turkish']\n",
    "    if len(line) != 0:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = line.translate(translate_table)\n",
    "        data_tur.append(line)\n",
    "        lang_tur.append(\"Turkish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92211bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_far = []\n",
    "lang_far = []\n",
    "\n",
    "for i,line in far_df.iterrows():\n",
    "    line = line['Farsi']\n",
    "    if len(line) != 0:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = re.sub(r\"[a-zA-Z]+\", \"\", line)\n",
    "        line = line.translate(translate_table)\n",
    "        data_far.append(line)\n",
    "        lang_far.append(\"Farsi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf77ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jap = []\n",
    "lang_jap = []\n",
    "\n",
    "for i,line in jap_df.iterrows():\n",
    "    line = line['Japanese']\n",
    "    if len(line) != 0:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"\\d+\", \"\", line)\n",
    "        line = re.sub(r\"[a-zA-Z]+\", \"\", line)\n",
    "        line = line.translate(translate_table)\n",
    "        data_jap.append(line)\n",
    "        lang_jap.append(\"Japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bfbce34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Text\": data_eng+data_tur+data_far+data_jap,\n",
    "                   \"language\":lang_eng+lang_tur+lang_far+lang_jap})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adb77c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  language\n",
      "0  i woke up early this morning and enjoyed a pea...   English\n",
      "1  bu sabah erken kalktım ve parkta huzurlu bir y...   Turkish\n",
      "2  امروز صبح زود بیدار شدم و یک قدم آرام در پارک ...     Farsi\n",
      "3                                                日本語  Japanese\n",
      "4  今朝は早く起きて、公園で静かな散歩を楽しみました。やわらかな葉のさらさらという音や鳥のさえず...  Japanese\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a81c367",
   "metadata": {},
   "source": [
    "## Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2015e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(1,)\n",
      "(4,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "X, y = df.iloc[:,0], df.iloc[:,1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b93a495",
   "metadata": {},
   "source": [
    "## Vector and model fitting pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a636ab63",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.feature_extraction.text' has no attribute 'TfidVectorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_extraction\n\u001b[1;32m----> 4\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m feature_extraction\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mTfidVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m), analyzer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m pipe_lr_r13 \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mPipeline([\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m, vectorizer),\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, linear_model\u001b[38;5;241m.\u001b[39mLogisticRegression())\n\u001b[0;32m      8\u001b[0m ])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sklearn.feature_extraction.text' has no attribute 'TfidVectorizer'"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_extraction\n",
    "\n",
    "\n",
    "vectorizer = feature_extraction.text.TfidVectorizer(ngram_range=(1,3), analyzer='char')\n",
    "pipe_lr_r13 = pipeline.Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('clf', linear_model.LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e26117",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_r13.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
